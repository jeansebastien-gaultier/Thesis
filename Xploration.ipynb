{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3455e694-4919-4716-8236-511c24b273f9",
   "metadata": {},
   "source": [
    "# Xploration Notebook\n",
    "\n",
    "In this notebook we will build a first method to find the frequency of words in a corpus and see their relevance.\n",
    "\n",
    "We will work with the corpus of EHR (CSV files - Lounes), and then build the TF and then IDF model.\n",
    "\n",
    "WE will then try to have visualization aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89d6f8b-0871-42ba-a6bb-d26ee44b8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451610e5-2999-433f-a82a-6c2d14e36f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the csv file to analyze\n",
    "TEST = {1: \"le tf-idf de l'anglais term frequency-inverse document frequency est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes\",\n",
    "       2: \"cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document relativement à une collection ou un corpus\",\n",
    "       3: \"le poids augmente proportionnellement au nombre d'occurrences du mot dans le document\",\n",
    "       4: \"il varie également en fonction de la fréquence du mot dans le corpus ainsi le\",\n",
    "       5: \"des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur\"}\n",
    "df = pd.DataFrame.from_dict(TEST, orient = 'index')\n",
    "#df[1] = [element[0].split() for _, element in df.iterrows()]\n",
    "all_words = set([word for _, words in df.iterrows() for word in words[0].split() for _, words in df.iterrows()])\n",
    "all_words_dict = {word:0 for word in all_words}\n",
    "#df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d58401ee",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2f346c1",
   "metadata": {},
   "source": [
    "### Basic Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80762c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ainsi</th>\n",
       "      <th>apprécier</th>\n",
       "      <th>au</th>\n",
       "      <th>augmente</th>\n",
       "      <th>cette</th>\n",
       "      <th>collection</th>\n",
       "      <th>contenu</th>\n",
       "      <th>corpus</th>\n",
       "      <th>critères</th>\n",
       "      <th>d'information</th>\n",
       "      <th>...</th>\n",
       "      <th>textes</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>un</th>\n",
       "      <th>une</th>\n",
       "      <th>utilisée</th>\n",
       "      <th>utilisées</th>\n",
       "      <th>variantes</th>\n",
       "      <th>varie</th>\n",
       "      <th>à</th>\n",
       "      <th>également</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ainsi  apprécier  au  augmente  cette  collection  contenu  corpus  \\\n",
       "0      0          0   0         0      0           0        0       0   \n",
       "1      0          0   0         0      1           1        1       1   \n",
       "2      0          0   1         1      0           0        0       0   \n",
       "3      1          0   0         0      0           0        0       1   \n",
       "4      0          1   0         0      0           0        0       0   \n",
       "\n",
       "   critères  d'information  ...  textes  tf-idf  un  une  utilisée  utilisées  \\\n",
       "0         0              1  ...       1       1   0    1         1          0   \n",
       "1         0              0  ...       0       0   2    1         0          0   \n",
       "2         0              0  ...       0       0   0    0         0          0   \n",
       "3         0              0  ...       0       0   0    0         0          0   \n",
       "4         1              0  ...       0       0   0    0         0          1   \n",
       "\n",
       "   variantes  varie  à  également  \n",
       "0          0      0  0          0  \n",
       "1          0      0  1          0  \n",
       "2          0      0  0          0  \n",
       "3          0      1  0          1  \n",
       "4          1      0  0          0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_dict = {word: 0 for word in all_words}\n",
    "all_words_dict = {key: value for key, value in sorted(all_words_dict.items())}\n",
    "sentences_dict = {i:all_words_dict.copy() for i in list(TEST.keys())}\n",
    "\n",
    "for k, sentence in TEST.items():\n",
    "    for word in sentence.split():\n",
    "        sentences_dict[k][word] +=1\n",
    "        \n",
    "X_bow = []\n",
    "for i in list(TEST.keys()):\n",
    "    X_bow.append(list(sentences_dict[i].values()))\n",
    "\n",
    "df_bow = pd.DataFrame(X_bow, columns = [i for i in list(all_words_dict.keys())])\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_count_text(doc):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w]+=1\n",
    "    return words\n",
    "\n",
    "dict_df = {i:{} for i in range(len(TEST))}\n",
    "i=0\n",
    "for k, sentence in TEST.items():\n",
    "    dict_df[i] = raw_count_text(sentence)\n",
    "    i+=1\n",
    "\n",
    "df  = pd.DataFrame.from_dict(dict_df, orient = 'index')\n",
    "df\n",
    "\n",
    "X_home = []\n",
    "for idx, row in df.iterrows():\n",
    "    a = list(row)\n",
    "    a = [0 if math.isnan(num) else int(num) for num in a]\n",
    "    X_home.append(a)\n",
    "X_home = np.array(X_home)\n",
    "df_CV = pd.DataFrame(X_home, columns = [i for i in range(len(X_home[0]))])\n",
    "df_CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1329c01",
   "metadata": {},
   "source": [
    "### Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23fb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8462eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(list(TEST.values()))\n",
    "X = X.toarray()\n",
    "X\n",
    "df_CV = pd.DataFrame(X, columns = [i for i in range(len(X[0]))])\n",
    "df_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962bef02-c9b2-4810-a25e-25e0ca00f30b",
   "metadata": {},
   "source": [
    "## TF aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1584e0d0-e366-4473-8459-d80096b212b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the count in each document\n",
    "def raw_count_text(doc):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w]+=1\n",
    "    return words\n",
    "    \n",
    "def term_frequency_text(doc, log = False):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the frequency of a word within the text\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w] +=1\n",
    "    if log == True:\n",
    "        words = {k:np.log(1+v) for k,v in words.items()}\n",
    "    else:\n",
    "        words = {k:(v*100)/sum(words.values()) for k,v in words.items()}\n",
    "    return words\n",
    "\n",
    "def bool_frequency(doc):\n",
    "    words = {}\n",
    "    for w in all_words:\n",
    "        if w in doc.split():\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w] = 0\n",
    "    return words\n",
    "\n",
    "# Finding the count for the whole corpus\n",
    "def raw_count_corpus(data):\n",
    "    \"\"\"\n",
    "    Given a data frame composed of text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for _, string in data.iterrows():\n",
    "        for w in string[0].split():\n",
    "            if w not in words:\n",
    "                words[w] = 1\n",
    "            else:\n",
    "                words[w]+=1\n",
    "    return words\n",
    "    \n",
    "def term_frequency_corpus(data, log = False):\n",
    "    \"\"\"\n",
    "    Given a dataframe composed of texts, return a dictionnary with the frequency of a word within the corpus\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for _, string in data.iterrows():\n",
    "        for w in string[0].split():\n",
    "            if w not in words:\n",
    "                words[w] = 1\n",
    "            else:\n",
    "                words[w] +=1\n",
    "    if log == True:\n",
    "        words = {k:np.log(1+v) for k,v in words.items()}\n",
    "    else:\n",
    "        words = {k:(v*100)/sum(words.values()) for k,v in words.items()}\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5076f-4a7a-4b90-ac2d-e6e492cc0eb5",
   "metadata": {},
   "source": [
    "## IDF aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad620fb1-6f35-47df-ab40-8845bdaf2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IDF\n",
    "def idf(data):\n",
    "    N = data.shape[0]\n",
    "    frequency = {}\n",
    "    for _, word in data.iterrows():\n",
    "        bf = bool_frequency(word[0])\n",
    "        for k,v in bf.items():\n",
    "            if v == 1:\n",
    "                if k not in frequency:\n",
    "                    frequency[k] = 1\n",
    "                else:\n",
    "                    frequency[k] +=1\n",
    "    return frequency\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e969e39",
   "metadata": {},
   "source": [
    "## TF-IDF together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "idf_data = idf(df)\n",
    "tfidf = {i:{word:0 for word, _ in idf_data.items()} for i in range(df.shape[0])}\n",
    "i=0\n",
    "for _, text in df.iterrows():\n",
    "    a = term_frequency_text(text[0])\n",
    "    for word, freq in a.items():\n",
    "        tfidf[i][word] = freq * idf_data[word]\n",
    "    i+=1\n",
    "X_home_tfidf = pd.DataFrame.from_dict(tfidf, orient = 'index')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47c4c1ab",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(TEST.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eff683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801206b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = X.toarray()\n",
    "df_tfidf = pd.DataFrame(X_tfidf, columns = [i for i in range(len(X_tfidf[0]))])\n",
    "df_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d4249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SogLab_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e094d850592d944b38bb8613998c40358239c031dd4b8b0f43e97425e6f0245d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
