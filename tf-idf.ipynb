{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3455e694-4919-4716-8236-511c24b273f9",
   "metadata": {},
   "source": [
    "# TF-IDF notebook\n",
    "\n",
    "In this notebook we will build a first method to find the frequency of words in a corpus and see their relevance.\n",
    "\n",
    "We will work with the corpus of EHR (CSV files - Lounes), and then build the TF and then IDF model.\n",
    "\n",
    "WE will then try to have visualization aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b89d6f8b-0871-42ba-a6bb-d26ee44b8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "451610e5-2999-433f-a82a-6c2d14e36f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the csv file to analyze\n",
    "TEST = {1: \"le tf-idf de l'anglais term frequency-inverse document frequency est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes\",\n",
    "       2: \"cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document relativement à une collection ou un corpus\",\n",
    "       3: \"le poids augmente proportionnellement au nombre d'occurrences du mot dans le document\",\n",
    "       4: \"il varie également en fonction de la fréquence du mot dans le corpus ainsi le\",\n",
    "       5: \"des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur\"}\n",
    "df = pd.DataFrame.from_dict(TEST, orient = 'index')\n",
    "#df[1] = [element[0].split() for _, element in df.iterrows()]\n",
    "all_words = set([word for _, words in df.iterrows() for word in words[0].split() for _, words in df.iterrows()])\n",
    "all_words_dict = {word:0 for word in all_words}\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962bef02-c9b2-4810-a25e-25e0ca00f30b",
   "metadata": {},
   "source": [
    "## TF aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1584e0d0-e366-4473-8459-d80096b212b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the count in each document\n",
    "def raw_count_text(doc):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w]+=1\n",
    "    return words\n",
    "    \n",
    "def term_frequency_text(doc, log = False):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the frequency of a word within the text\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w] +=1\n",
    "    if log == True:\n",
    "        words = {k:np.log(1+v) for k,v in words.items()}\n",
    "    else:\n",
    "        words = {k:(v*100)/sum(words.values()) for k,v in words.items()}\n",
    "    return words\n",
    "\n",
    "def bool_frequency(doc):\n",
    "    words = {}\n",
    "    for w in all_words:\n",
    "        if w in doc.split():\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w] = 0\n",
    "    return words\n",
    "\n",
    "# Finding the count for the whole corpus\n",
    "def raw_count_corpus(data):\n",
    "    \"\"\"\n",
    "    Given a data frame composed of text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for _, string in data.iterrows():\n",
    "        for w in string[0].split():\n",
    "            if w not in words:\n",
    "                words[w] = 1\n",
    "            else:\n",
    "                words[w]+=1\n",
    "    return words\n",
    "    \n",
    "def term_frequency_corpus(data, log = False):\n",
    "    \"\"\"\n",
    "    Given a dataframe composed of texts, return a dictionnary with the frequency of a word within the corpus\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for _, string in data.iterrows():\n",
    "        for w in string[0].split():\n",
    "            if w not in words:\n",
    "                words[w] = 1\n",
    "            else:\n",
    "                words[w] +=1\n",
    "    if log == True:\n",
    "        words = {k:np.log(1+v) for k,v in words.items()}\n",
    "    else:\n",
    "        words = {k:(v*100)/sum(words.values()) for k,v in words.items()}\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5076f-4a7a-4b90-ac2d-e6e492cc0eb5",
   "metadata": {},
   "source": [
    "## IDF aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad620fb1-6f35-47df-ab40-8845bdaf2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IDF\n",
    "def idf(data):\n",
    "    N = data.shape[0]\n",
    "    frequency = {}\n",
    "    for _, word in data.iterrows():\n",
    "        bf = bool_frequency(word[0])\n",
    "        for k,v in bf.items():\n",
    "            if v == 1:\n",
    "                if k not in frequency:\n",
    "                    frequency[k] = 1\n",
    "                else:\n",
    "                    frequency[k] +=1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1cebd93-c200-498b-b7ae-11ae93670296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'particulier': 1,\n",
       " 'le': 3,\n",
       " 'term': 1,\n",
       " 'méthode': 1,\n",
       " 'utilisée': 1,\n",
       " 'une': 2,\n",
       " 'pondération': 1,\n",
       " 'dans': 5,\n",
       " 'fouille': 1,\n",
       " 'document': 4,\n",
       " \"l'anglais\": 1,\n",
       " 'en': 3,\n",
       " 'est': 1,\n",
       " 'frequency': 1,\n",
       " 'textes': 1,\n",
       " 'tf-idf': 1,\n",
       " 'souvent': 2,\n",
       " 'recherche': 2,\n",
       " 'la': 3,\n",
       " \"d'information\": 1,\n",
       " 'et': 1,\n",
       " 'frequency-inverse': 1,\n",
       " 'de': 3,\n",
       " 'statistique': 1,\n",
       " 'terme': 1,\n",
       " 'ou': 1,\n",
       " 'cette': 1,\n",
       " \"d'évaluer\": 1,\n",
       " 'contenu': 1,\n",
       " 'relativement': 1,\n",
       " 'un': 1,\n",
       " 'collection': 1,\n",
       " 'à': 1,\n",
       " \"d'un\": 2,\n",
       " 'permet': 1,\n",
       " 'mesure': 1,\n",
       " \"l'importance\": 1,\n",
       " 'corpus': 2,\n",
       " 'nombre': 1,\n",
       " 'mot': 2,\n",
       " 'poids': 1,\n",
       " 'proportionnellement': 1,\n",
       " 'du': 2,\n",
       " 'augmente': 1,\n",
       " 'au': 1,\n",
       " \"d'occurrences\": 1,\n",
       " 'il': 1,\n",
       " 'fonction': 2,\n",
       " 'ainsi': 1,\n",
       " 'fréquence': 1,\n",
       " 'varie': 1,\n",
       " 'également': 1,\n",
       " 'moteurs': 1,\n",
       " 'originale': 1,\n",
       " 'sont': 1,\n",
       " 'critères': 1,\n",
       " 'formule': 1,\n",
       " 'variantes': 1,\n",
       " 'pertinence': 1,\n",
       " \"l'utilisateur\": 1,\n",
       " 'des': 1,\n",
       " 'utilisées': 1,\n",
       " 'apprécier': 1,\n",
       " 'pour': 1}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JS_venv_data_science_1",
   "language": "python",
   "name": "js_venv_data_science_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
