{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3455e694-4919-4716-8236-511c24b273f9",
   "metadata": {},
   "source": [
    "# TF-IDF notebook\n",
    "\n",
    "In this notebook we will build a first method to find the frequency of words in a corpus and see their relevance.\n",
    "\n",
    "We will work with the corpus of EHR (CSV files - Lounes), and then build the TF and then IDF model.\n",
    "\n",
    "WE will then try to have visualization aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89d6f8b-0871-42ba-a6bb-d26ee44b8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451610e5-2999-433f-a82a-6c2d14e36f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the csv file to analyze\n",
    "TEST = {1: \"le tf-idf de l'anglais term frequency-inverse document frequency est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes\",\n",
    "       2: \"cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document relativement à une collection ou un corpus\",\n",
    "       3: \"le poids augmente proportionnellement au nombre d'occurrences du mot dans le document\",\n",
    "       4: \"il varie également en fonction de la fréquence du mot dans le corpus ainsi le\",\n",
    "       5: \"des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur\"}\n",
    "df = pd.DataFrame.from_dict(TEST, orient = 'index')\n",
    "#df[1] = [element[0].split() for _, element in df.iterrows()]\n",
    "all_words = set([word for _, words in df.iterrows() for word in words[0].split() for _, words in df.iterrows()])\n",
    "all_words_dict = {word:0 for word in all_words}\n",
    "#df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d58401ee",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbd8766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>le</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>de</th>\n",
       "      <th>l'anglais</th>\n",
       "      <th>term</th>\n",
       "      <th>frequency-inverse</th>\n",
       "      <th>document</th>\n",
       "      <th>frequency</th>\n",
       "      <th>est</th>\n",
       "      <th>une</th>\n",
       "      <th>...</th>\n",
       "      <th>formule</th>\n",
       "      <th>originale</th>\n",
       "      <th>sont</th>\n",
       "      <th>utilisées</th>\n",
       "      <th>moteurs</th>\n",
       "      <th>pour</th>\n",
       "      <th>apprécier</th>\n",
       "      <th>pertinence</th>\n",
       "      <th>critères</th>\n",
       "      <th>l'utilisateur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    le  tf-idf   de  l'anglais  term  frequency-inverse  document  frequency  \\\n",
       "0  1.0     1.0  3.0        1.0   1.0                1.0       1.0        1.0   \n",
       "2  2.0     NaN  NaN        NaN   NaN                NaN       1.0        NaN   \n",
       "3  2.0     NaN  1.0        NaN   NaN                NaN       NaN        NaN   \n",
       "4  NaN     NaN  4.0        NaN   NaN                NaN       1.0        NaN   \n",
       "1  NaN     NaN  NaN        NaN   NaN                NaN       1.0        NaN   \n",
       "\n",
       "   est  une  ...  formule  originale  sont  utilisées  moteurs  pour  \\\n",
       "0  1.0  1.0  ...      NaN        NaN   NaN        NaN      NaN   NaN   \n",
       "2  NaN  NaN  ...      NaN        NaN   NaN        NaN      NaN   NaN   \n",
       "3  NaN  NaN  ...      NaN        NaN   NaN        NaN      NaN   NaN   \n",
       "4  NaN  NaN  ...      1.0        1.0   1.0        1.0      1.0   1.0   \n",
       "1  NaN  1.0  ...      NaN        NaN   NaN        NaN      NaN   NaN   \n",
       "\n",
       "   apprécier  pertinence  critères  l'utilisateur  \n",
       "0        NaN         NaN       NaN            NaN  \n",
       "2        NaN         NaN       NaN            NaN  \n",
       "3        NaN         NaN       NaN            NaN  \n",
       "4        1.0         1.0       1.0            1.0  \n",
       "1        NaN         NaN       NaN            NaN  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def raw_count_text(doc):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w]+=1\n",
    "    return words\n",
    "\n",
    "dict_df = {}\n",
    "i=0\n",
    "for k, sentence in TEST.items():\n",
    "    dict_df[i] = raw_count_text(sentence)\n",
    "    i+=1\n",
    "\n",
    "df  = pd.DataFrame.from_dict(dict_df, orient = 'index')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962bef02-c9b2-4810-a25e-25e0ca00f30b",
   "metadata": {},
   "source": [
    "## TF aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1584e0d0-e366-4473-8459-d80096b212b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the count in each document\n",
    "def raw_count_text(doc):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w]+=1\n",
    "    return words\n",
    "    \n",
    "def term_frequency_text(doc, log = False):\n",
    "    \"\"\"\n",
    "    Given a text, return a dictionnary with the frequency of a word within the text\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for w in doc.split():\n",
    "        if w not in words:\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w] +=1\n",
    "    if log == True:\n",
    "        words = {k:np.log(1+v) for k,v in words.items()}\n",
    "    else:\n",
    "        words = {k:(v*100)/sum(words.values()) for k,v in words.items()}\n",
    "    return words\n",
    "\n",
    "def bool_frequency(doc):\n",
    "    words = {}\n",
    "    for w in all_words:\n",
    "        if w in doc.split():\n",
    "            words[w] = 1\n",
    "        else:\n",
    "            words[w] = 0\n",
    "    return words\n",
    "\n",
    "# Finding the count for the whole corpus\n",
    "def raw_count_corpus(data):\n",
    "    \"\"\"\n",
    "    Given a data frame composed of text, return a dictionnary with the amount of occurences of a word\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for _, string in data.iterrows():\n",
    "        for w in string[0].split():\n",
    "            if w not in words:\n",
    "                words[w] = 1\n",
    "            else:\n",
    "                words[w]+=1\n",
    "    return words\n",
    "    \n",
    "def term_frequency_corpus(data, log = False):\n",
    "    \"\"\"\n",
    "    Given a dataframe composed of texts, return a dictionnary with the frequency of a word within the corpus\n",
    "    \"\"\"\n",
    "    words = {}\n",
    "    for _, string in data.iterrows():\n",
    "        for w in string[0].split():\n",
    "            if w not in words:\n",
    "                words[w] = 1\n",
    "            else:\n",
    "                words[w] +=1\n",
    "    if log == True:\n",
    "        words = {k:np.log(1+v) for k,v in words.items()}\n",
    "    else:\n",
    "        words = {k:(v*100)/sum(words.values()) for k,v in words.items()}\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5076f-4a7a-4b90-ac2d-e6e492cc0eb5",
   "metadata": {},
   "source": [
    "## IDF aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad620fb1-6f35-47df-ab40-8845bdaf2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IDF\n",
    "def idf(data):\n",
    "    N = data.shape[0]\n",
    "    frequency = {}\n",
    "    for _, word in data.iterrows():\n",
    "        bf = bool_frequency(word[0])\n",
    "        for k,v in bf.items():\n",
    "            if v == 1:\n",
    "                if k not in frequency:\n",
    "                    frequency[k] = 1\n",
    "                else:\n",
    "                    frequency[k] +=1\n",
    "    return frequency\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e969e39",
   "metadata": {},
   "source": [
    "## TF-IDF together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fouille</th>\n",
       "      <th>frequency</th>\n",
       "      <th>dans</th>\n",
       "      <th>utilisée</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>est</th>\n",
       "      <th>souvent</th>\n",
       "      <th>textes</th>\n",
       "      <th>document</th>\n",
       "      <th>d'information</th>\n",
       "      <th>...</th>\n",
       "      <th>pour</th>\n",
       "      <th>des</th>\n",
       "      <th>originale</th>\n",
       "      <th>moteurs</th>\n",
       "      <th>l'utilisateur</th>\n",
       "      <th>utilisées</th>\n",
       "      <th>pertinence</th>\n",
       "      <th>variantes</th>\n",
       "      <th>sont</th>\n",
       "      <th>critères</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.846154</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>10.714286</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fouille  frequency       dans  utilisée    tf-idf       est   souvent  \\\n",
       "0  3.846154   3.846154  19.230769  3.846154  3.846154  3.846154  7.692308   \n",
       "1  0.000000   0.000000  26.315789  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000   0.000000  41.666667  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000   0.000000  33.333333  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000   0.000000  17.857143  0.000000  0.000000  0.000000  7.142857   \n",
       "\n",
       "     textes   document  d'information  ...      pour        des  originale  \\\n",
       "0  3.846154  15.384615       3.846154  ...  0.000000   0.000000   0.000000   \n",
       "1  0.000000  21.052632       0.000000  ...  0.000000   0.000000   0.000000   \n",
       "2  0.000000  33.333333       0.000000  ...  0.000000   0.000000   0.000000   \n",
       "3  0.000000   0.000000       0.000000  ...  0.000000   0.000000   0.000000   \n",
       "4  0.000000  14.285714       0.000000  ...  3.571429  10.714286   3.571429   \n",
       "\n",
       "    moteurs  l'utilisateur  utilisées  pertinence  variantes      sont  \\\n",
       "0  0.000000       0.000000   0.000000    0.000000   0.000000  0.000000   \n",
       "1  0.000000       0.000000   0.000000    0.000000   0.000000  0.000000   \n",
       "2  0.000000       0.000000   0.000000    0.000000   0.000000  0.000000   \n",
       "3  0.000000       0.000000   0.000000    0.000000   0.000000  0.000000   \n",
       "4  3.571429       3.571429   3.571429    3.571429   3.571429  3.571429   \n",
       "\n",
       "   critères  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  3.571429  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = {}\n",
    "idf_data = idf(df)\n",
    "tfidf = {i:{word:0 for word, _ in idf_data.items()} for i in range(df.shape[0])}\n",
    "i=0\n",
    "for _, text in df.iterrows():\n",
    "    a = term_frequency_text(text[0])\n",
    "    for word, freq in a.items():\n",
    "        tfidf[i][word] = freq * idf_data[word]\n",
    "    i+=1\n",
    "pd.DataFrame.from_dict(tfidf, orient = 'index')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47c4c1ab",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb4c98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e868c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(TEST.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8753de28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"le tf-idf de l'anglais term frequency-inverse document frequency est une méthode de pondération souvent utilisée en recherche d'information et en particulier dans la fouille de textes\",\n",
       " \"cette mesure statistique permet d'évaluer l'importance d'un terme contenu dans un document relativement à une collection ou un corpus\",\n",
       " \"le poids augmente proportionnellement au nombre d'occurrences du mot dans le document\",\n",
       " 'il varie également en fonction de la fréquence du mot dans le corpus ainsi le',\n",
       " \"des variantes de la formule originale sont souvent utilisées dans des moteurs de recherche pour apprécier la pertinence d'un document en fonction des critères de recherche de l'utilisateur\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2da8926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89eff683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a50e67e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ainsi', 'anglais', 'apprécier', 'au', 'augmente', 'cette',\n",
       "       'collection', 'contenu', 'corpus', 'critères', 'dans', 'de', 'des',\n",
       "       'document', 'du', 'en', 'est', 'et', 'fonction', 'formule',\n",
       "       'fouille', 'frequency', 'fréquence', 'idf', 'il', 'importance',\n",
       "       'information', 'inverse', 'la', 'le', 'mesure', 'mot', 'moteurs',\n",
       "       'méthode', 'nombre', 'occurrences', 'originale', 'ou',\n",
       "       'particulier', 'permet', 'pertinence', 'poids', 'pondération',\n",
       "       'pour', 'proportionnellement', 'recherche', 'relativement', 'sont',\n",
       "       'souvent', 'statistique', 'term', 'terme', 'textes', 'tf', 'un',\n",
       "       'une', 'utilisateur', 'utilisée', 'utilisées', 'variantes',\n",
       "       'varie', 'également', 'évaluer'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d801206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 63)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d575f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x63 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 86 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d4249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JS_venv_data_science_1",
   "language": "python",
   "name": "js_venv_data_science_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
